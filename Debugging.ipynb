{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install jupyter matplotlib\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multispecies_whale_detection import front_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multispecies_whale_detection import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0855310",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.expanduser('~/tmp/whale_data')\n",
    "batch_size = 128\n",
    "sample_rate = 4000.0\n",
    "class_names = ['Orca', 'SRKW', 'IBKW', 'Ej']\n",
    "window_duration = 2.0\n",
    "\n",
    "def configured_window_dataset(\n",
    "  input_subdirectory: str,\n",
    "  windowing: dataset.Windowing,\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"Creates a Dataset, binding arguments shared by train and validation.\"\"\"\n",
    "    return dataset.new_window_dataset(\n",
    "        tfrecord_filepattern=os.path.join(base_dir, 'input', input_subdirectory,\n",
    "                                          'tfrecords-*'),\n",
    "        windowing=windowing,\n",
    "        duration=window_duration,\n",
    "        class_names=class_names,\n",
    "        min_overlap=0.25,\n",
    "    )\n",
    "\n",
    "train_dataset = configured_window_dataset(\n",
    "  'train',\n",
    "  dataset.RandomWindowing(4),\n",
    ").cache().repeat().shuffle(batch_size * 4).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "      front_end.Spectrogram(\n",
    "          front_end.SpectrogramConfig(\n",
    "              sample_rate=sample_rate,\n",
    "              frame_seconds=0.05,\n",
    "              hop_seconds=0.025,\n",
    "              frequency_scaling=front_end.MelScalingConfig(\n",
    "                  lower_edge_hz=125.0,\n",
    "                  num_mel_bins=64,\n",
    "              ))),\n",
    "      front_end.SpectrogramToImage(sgram_min=-323, sgram_max=-99),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8279430",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, labels = next(iter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(waveform.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tf.math.reduce_mean(images), tf.math.reduce_std(images), tf.math.reduce_min(images), tf.math.reduce_max(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272af7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e848808",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 20\n",
    "limit = 10\n",
    "\n",
    "for image, label_batch in itertools.islice(zip(images, labels), offset, offset +limit):\n",
    "    plt.imshow(tf.cast(image, tf.int32))\n",
    "    plt.title(label_batch.numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_counts = []\n",
    "for _, label_batch in itertools.islice(iter(train_dataset), 5):\n",
    "    batch_counts.append(tf.math.reduce_sum(label_batch, axis=0))\n",
    "batch_counts = tf.stack(batch_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce68262",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = batch_counts.shape[-1]\n",
    "for class_index in range(num_classes):\n",
    "    class_counts = batch_counts[:, class_index]\n",
    "    plt.hist(class_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f28ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whale_env",
   "language": "python",
   "name": "whale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
